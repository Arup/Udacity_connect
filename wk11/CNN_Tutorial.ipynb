{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect Intensive - Machine Learning Nanodegree\n",
    "\n",
    "## Week 11. Image Classification using CNN\n",
    "\n",
    "### Objectives    \n",
    "\n",
    "  - Build convolutional neural network to classify images from the CIFAR-10 dataset\n",
    "  \n",
    "### Prerequisites\n",
    "  - [numpy](http://www.scipy.org/scipylib/download.html)  \n",
    "  - [matplotlib](http://matplotlib.org/index.html)  \n",
    "  - [tensorflow](https://www.tensorflow.org)\n",
    "  - [keras](https://keras.io) \n",
    "  - [sklearn](http://scikit-learn.org/stable/index.html)  \n",
    "  - [seaborn](https://seaborn.pydata.org)  \n",
    "  \n",
    "### Installation  \n",
    "If you haven't installed TensorFlow and Keras, run the commands below for installation:  \n",
    "  - Install TensorFlow: `pip install tensorflow` (or `conda install tensorflow` if you use Anaconda distribution). Note that TensorFlow supports Python 3.5.x and 3.6.x on Windows.   \n",
    "  - Install Keras: `pip install keras` (or `conda install -c conda-forge keras` if you use Anaconda distribution). Note that the installation of Keras requires either tensorflow or theano installation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About CIFAR Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html). The dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. \n",
    "\n",
    "Here are the classes in the dataset, as well as 10 random images from each. The classes include airplanes, dogs, cats, and other objects. \n",
    "\n",
    "<img src=\"./imgs/CIFAR.png\", width=600px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all modules\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "if K.backend()=='tensorflow':\n",
    "    K.set_image_dim_ordering(\"th\")\n",
    "    \n",
    "import tensorflow as tf\n",
    "import multiprocessing as mp\n",
    " \n",
    "# Loading the CIFAR-10 datasets\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a good practice suggests, we need to declare our variables:\n",
    "\n",
    "- `batch_size` – the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you’ll need  \n",
    "- `num_classes` – number of cifar-10 data set classes  \n",
    "- `one epoch` – one forward pass and one backward pass of all the training examples  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare variables\n",
    "batch_size = 32 \n",
    "# 32 examples in a mini-batch, smaller batch size means more updates in one epoch\n",
    " \n",
    "num_classes = 10 #\n",
    "epochs = 10 # repeat 100 times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can load the CIFAR-10 data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train - training data(images), y_train - labels(digits)\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take a look at the images from each class in the CIFAR-10 dataset using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show figure with 10 random images from each class\n",
    "fig = plt.figure(figsize=(8, 3))\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(num_classes):\n",
    "    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
    "    idx = np.where(y_train[:]==i)[0]\n",
    "    features_idx = x_train[idx,::]\n",
    "    img_num = np.random.randint(features_idx.shape[0])\n",
    "    im = np.transpose(features_idx[img_num,::],(1,2,0))\n",
    "    ax.set_title(class_names[i])\n",
    "    plt.imshow(im)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixel values are in the range of 0 to 255 for each of the red, green and blue channels. It’s good practice to work with normalized data. Because the input values are well understood, we can easily normalize to the range 0 to 1 (inclusive) by dividing each value by the maximum observation which is 255.\n",
    "\n",
    "*Note*, the data is loaded as integers, so we must cast it to floating point values in order to perform the division since we are working with Python 2.\n",
    "\n",
    "The output variables are defined as a vector of integers from 0 to 1 for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert and pre-processing\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train  /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build our CNN (Convolutional Neural Networks)  we will use Keras. As introduced in last session, Keras is an open source neural network Python library which can run on top of other machine learning libraries like TensorFlow, CNTK or Theano. It allows for an easy and fast prototyping, supports convolutional,  recurrent neural networks and a combination of the two.\n",
    "\n",
    "We will use a model with two convolutional layers followed by max pooling, attached with a fully connected layer to make predictions:\n",
    "\n",
    "- Convolutional input layer, 16 filters with a size of 3×3, a relu activation function\n",
    "- Max Pool layer with size 2×2\n",
    "- Convolutional input layer, 32 filters with a size of 3×3, a relu activation function\n",
    "- Max Pool layer with size 2×2\n",
    "- Global average pooling layer  \n",
    "- Fully connected output layer with 10 units and a softmax activation function  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), padding='same', input_shape=x_train.shape[1:], activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr = 0.1, decay=1e-6, momentum=0.9, nesterov=True) # optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model_fitted = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training process, we can see loss and accuracy on plots using the code below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for training and testing process: loss and accuracy\n",
    "plt.figure(0)\n",
    "plt.plot(model_fitted.history['acc'],'r')\n",
    "plt.plot(model_fitted.history['val_acc'],'g')\n",
    "plt.xticks(np.arange(0, 15, 2.0))\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.xlabel('Num of Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy vs Validation Accuracy')\n",
    "plt.legend(['train', 'validation'])\n",
    " \n",
    "plt.figure(1)\n",
    "plt.plot(model_fitted.history['loss'],'r')\n",
    "plt.plot(model_fitted.history['val_loss'],'g')\n",
    "plt.xticks(np.arange(0, 15, 2.0))\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.xlabel('Num of Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss vs Validation Loss')\n",
    "plt.legend(['train', 'validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    " \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "Y_pred = model.predict(x_test, verbose=2)\n",
    "y_pred = np.argmax(Y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in range(10):\n",
    "    print(ix, confusion_matrix(np.argmax(y_test,axis=1), y_pred)[ix].sum())\n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
    "print(cm)\n",
    " \n",
    "# Visualizing of confusion matrix\n",
    "import seaborn as sns\n",
    "import pandas  as pd\n",
    "\n",
    "df_cm = pd.DataFrame(cm, range(10), range(10))\n",
    "plt.figure(figsize = (10, 7))\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "sns.heatmap(df_cm, annot=True, annot_kws={'size': 12})# font size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE \n",
    "\n",
    "Can you improve the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mlnd]",
   "language": "python",
   "name": "conda-env-mlnd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
